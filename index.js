#! /usr/bin/env node
/* eslint-disable no-unused-vars */

/*
----
MIXPANEL IMPORT
by AK
purpose: stream events, users, groups, tables into mixpanel... with best practices!
----
*/


/*
-----
DEPS
-----
*/

// $ job configuration
const importJob = require('./components/job.js');

// $ parsers
const { determineDataType, getEnvVars } = require("./components/parsers.js");

// $ pipelines
const { corePipeline } = require('./components/pipelines.js');

// $ env
require('dotenv').config();
const cliParams = require('./components/cli.js');
const { logger, writeLogs } = require('./components/logs.js');

// $ utils
const u = require('ak-tools');

// $ validators
const { validateToken } = require('./components/validators.js');

const dayjs = require('dayjs');
const utc = require('dayjs/plugin/utc');
dayjs.extend(utc);

/** @typedef {import('./index.d.ts').Creds} Creds */
/** @typedef {import('./index.d.ts').Data} Data */
/** @typedef {import('./index.d.ts').Options} Options */
/** @typedef {import('./index.d.ts').ImportResults} ImportResults */


/*
----
CORE
----
*/


/**
 * Mixpanel Importer
 * stream `events`, `users`, `groups`, and `tables` to mixpanel!
 * @function main
 * @example
 * const mp = require('mixpanel-import')
 * const imported = await mp(creds, data, options)
 * @param {Creds} creds - mixpanel project credentials
 * @param {Data} data - data to import
 * @param {Options} opts - import options
 * @param {boolean} isCLI - `true` when run as CLI
 * @returns {Promise<ImportResults>} API receipts of imported data
 */
async function main(creds = {}, data, opts = {}, isCLI = false) {
	let cliData = {};

	// gathering params
	const envVar = getEnvVars();
	let cli = {};
	if (isCLI) {
		cli = cliParams();
		cliData = cli._[0];
	}

	let hasPassedInCreds = Boolean(creds && Object.keys(creds).length);
	let finalCreds;
	if (hasPassedInCreds) finalCreds = creds;
	else if (isCLI) finalCreds = { ...envVar, ...cli };
	else finalCreds = envVar;

	let hasPassedInOpts = Boolean(opts && Object.keys(opts).length);
	let finalOpts;
	if (hasPassedInOpts) finalOpts = opts;
	else if (isCLI) finalOpts = { ...envVar, ...cli };
	else finalOpts = envVar;

	const job = new importJob(finalCreds, finalOpts);
	// const job = new importJob({ ...envVar, ...cli, ...creds }, { ...envVar, ...cli, ...opts });

	if (isCLI) job.verbose = true;
	const l = logger(job);
	if (isCLI) l(cliParams.welcome);
	if (isCLI) global.l = l; // hacky way to make logger available globally
	l(`\nðŸš€ MIXPANEL IMPORTER\n`);
	
	// Enhanced job creation logging with configuration details
	l(`\nâœ… JOB CREATED!\n`);
	if (job.verbose) {
		l(`â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—`);
		l(`â•‘                     CONFIGURATION SUMMARY                       â•‘`);
		l(`â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£`);
		l(`â•‘ Pipeline Configuration:                                         â•‘`);
		l(`â•‘   â€¢ Record Type: ${job.recordType.padEnd(47)}â•‘`);
		l(`â•‘   â€¢ Region: ${job.region.toUpperCase().padEnd(52)}â•‘`);
		l(`â•‘   â€¢ Stream Format: ${job.streamFormat.padEnd(45)}â•‘`);
		l(`â•‘                                                                  â•‘`);
		l(`â•‘ Performance Settings:                                           â•‘`);
		l(`â•‘   â€¢ Workers: ${String(job.workers).padEnd(51)}â•‘`);
		l(`â•‘   â€¢ High Water Mark: ${String(job.highWater).padEnd(43)}â•‘`);
		l(`â•‘   â€¢ Records per Batch: ${u.comma(job.recordsPerBatch).padEnd(41)}â•‘`);
		l(`â•‘   â€¢ Bytes per Batch: ${u.bytesHuman(job.bytesPerBatch).padEnd(43)}â•‘`);
		l(`â•‘   â€¢ Compression: ${job.compress ? 'Enabled' : 'Disabled'.padEnd(47)}â•‘`);

		// Data processing options
		if (job.vendor || job.transformFunc || job.fixData || job.fixTime || job.removeNulls) {
			l(`â•‘                                                                  â•‘`);
			l(`â•‘ Data Processing:                                                â•‘`);
			if (job.vendor) {
				const vendorText = `${job.vendor.toUpperCase()} vendor transform`;
				l(`â•‘   â€¢ Vendor: ${vendorText.padEnd(52)}â•‘`);
			}
			if (job.transformFunc) l(`â•‘   â€¢ Custom Transform: Enabled                                   â•‘`);
			if (job.fixData) l(`â•‘   â€¢ Fix Data: Enabled                                           â•‘`);
			if (job.fixTime) l(`â•‘   â€¢ Fix Time: Enabled                                           â•‘`);
			if (job.removeNulls) l(`â•‘   â€¢ Remove Nulls: Enabled                                       â•‘`);
			if (job.dedupe) l(`â•‘   â€¢ Deduplication: Enabled                                      â•‘`);
		}

		// Export specific settings
		if (job.recordType.includes('export')) {
			l(`â•‘                                                                  â•‘`);
			l(`â•‘ Export Settings:                                                â•‘`);
			l(`â•‘   â€¢ Export Mode: ${job.where ? (job.where.startsWith('gs://') ? 'â˜ï¸  GCS' : job.where.startsWith('s3://') ? 'â˜ï¸  S3' : 'ðŸ’¾ Local') : 'ðŸ’¾ Local'.padEnd(47)}â•‘`);
			if (job.params && Object.keys(job.params).length > 0) {
				const paramCount = Object.keys(job.params).length;
				l(`â•‘   â€¢ Export Params: ${String(paramCount) + ' parameter' + (paramCount > 1 ? 's' : '').padEnd(45)}â•‘`);
			}
		}

		// Memory management
		if (job.throttleGCS || job.throttleMemory || job.aggressiveGC) {
			l(`â•‘                                                                  â•‘`);
			l(`â•‘ Memory Management:                                              â•‘`);
			if (job.throttleGCS || job.throttleMemory) {
				l(`â•‘   â€¢ Memory Throttling: Enabled                                  â•‘`);
				l(`â•‘     - Pause at: ${u.bytesHuman((job.throttlePauseMB || 1500) * 1024 * 1024).padEnd(48)}â•‘`);
				l(`â•‘     - Resume at: ${u.bytesHuman((job.throttleResumeMB || 1000) * 1024 * 1024).padEnd(47)}â•‘`);
			}
			if (job.aggressiveGC) l(`â•‘   â€¢ Aggressive GC: Enabled (periodic + emergency)               â•‘`);
		}

		l(`â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
		l(``);
	}
	await job.init();
	l(`\nðŸ“¦ DEPS LOADED!\n`);

	// ETL
	l(`\nâš¡ ETL STARTED!\n`);
	// Timer is auto-started in Job constructor

	let stream;
	try {

		stream = await determineDataType(data || cliData, job); // always stream[]
		l(`\nðŸŒŠ STREAM CREATED!\n`);
	}
	catch (e) {
		l(`ERROR: Failed to create stream - ${e.message}`);
		if (isCLI) {
			process.exit(1);
		} else {
			throw e;
		}
	}

	try {

		await corePipeline(stream, job)
			.finally(() => {
				l(`\nSTREAM CONSUMED!\n`);
			});
	}

	catch (e) {
		l(`ERROR: ${e.message}`);
		if (e?.response?.body) l(`RESPONSE: ${u.json(e.response.body)}\n`);

		// Re-throw the error so tests and non-CLI usage can catch it
		if (!isCLI) {
			throw e;
		}
		// For CLI, we continue to show the summary even on error
	}

	l('\n');
	if (job.createProfiles)  //job.transform = await createProfiles(job);

	// clean up - stop timer before getting summary
	job.timer.stop(false);
	const summary = job.summary();
	// Always show completion message for exports (even when not CLI)
	const isExport = job.recordType && job.recordType.includes('export');
	if (isExport || isCLI) {
		l(`\nðŸŽ‰ ${isExport ? 'EXPORT' : 'IMPORT'} COMPLETE in ${summary.durationHuman}!\n`);
	}
	
	const stats = {
		total: u.comma(summary.total),
		success: u.comma(summary.success),
		failed: u.comma(summary.failed),
		bytes: summary.bytesHuman,
		requests: u.comma(summary.requests),
		"rate (per sec)": u.comma(summary.eps)
	};

	if (isCLI) {
		l("ðŸ“Š STATS");
		l(stats, true);
		l('\n');
	}
	
	// For verbose mode, show key info even when not CLI
	if (job.verbose && !isCLI) {
		if (job.recordType && job.recordType.includes('export')) {
			l(`ðŸ“Š ${u.comma(summary.success)} records exported in ${summary.durationHuman}`);
			if (job.where && (job.where.startsWith('gs://') || job.where.startsWith('s3://'))) {
				l(`â˜ï¸  Saved to: ${job.where}`);
			}
		} else {
			// Import summary
			l(`ðŸ“Š ${u.comma(summary.success)} records imported in ${summary.durationHuman}`);
			if (summary.failed > 0) {
				l(`âŒ ${u.comma(summary.failed)} records failed`);
			}
			if (summary.duplicates > 0) {
				l(`ðŸ”„ ${u.comma(summary.duplicates)} duplicates skipped`);
			}
			const rpsValue = summary.rps ? summary.rps.toFixed(2) : '0.00';
			l(`âš¡ ${u.comma(summary.eps || 0)} events/sec â€¢ ${rpsValue} requests/sec`);
		}
		l('');
	}

	if (job.logs) {
		const logPath = await writeLogs(summary);
		if (logPath && isCLI) {
			l(`ðŸ“ Log saved: ${logPath}`);
			// Output just the path on the last line for tests
			console.log(logPath);
		}
	}
	return summary;
}



/**
 * Mixpanel Streamer
 * this function returns a transform stream that takes in data and streams it to mixpanel
 * @param {Creds} creds - mixpanel project credentials
 * @param {Options} opts - import options
 * @param {function(): importJob | void} finish - end of pipelines
 * @returns a transform stream
 */
async function pipeInterface(creds = {}, opts = {}, finish = () => { }) {
	const envVar = getEnvVars();
	const config = new importJob({ ...envVar, ...creds }, { ...envVar, ...opts });
	// Timer is auto-started in Job constructor

	const pipeToMe = await corePipeline(null, config, true);

	// * handlers
	// @ts-ignore
	pipeToMe.on('finish', () => {
		config.timer.stop(false);

		// @ts-ignore
		finish(null, config.summary());
	});

	// @ts-ignore
	pipeToMe.on('pipe', () => {

		// @ts-ignore
		pipeToMe.resume();
	});

	// @ts-ignore
	pipeToMe.on('error', (e) => {
		if (config.verbose) {
			console.log(e);
		}
		// @ts-ignore
		finish(e, config.summary());
	});

	// Return the native stream directly
	return pipeToMe;
}


// async function createProfiles(job, record) {
// 	const { groupKey, token } = job;
// 	const profile = {
// 		$token: token,
// 		$ip: 0,
// 		$set: {}
// 	};

// 	if (groupKey) {
// 		profile.$group_key = groupKey;
// 		profile.$group_id = record[groupKey] || record.distinct_id || record.$distinct_id || record.user_id || record.$user_id;
// 		profile.$set.id = record[groupKey] || record.distinct_id || record.$distinct_id || record.user_id || record.$user_id;
// 	}
// 	if (!groupKey) {
// 		profile.$distinct_id = record.distinct_id || record.$distinct_id || record.user_id || record.$user_id;
// 		profile.$set.id = record.distinct_id || record.$distinct_id || record.user_id || record.$user_id;
// 	}

// 	return profile;

// 	job.recordType = 'user';
// 	const copyStream = await determineDataType(data || cliData, job);
// 	const copyPipeline = await corePipeline(copyStream, job);
// };

/*
-------
EXPORTS
-------
*/

main.validateToken = validateToken;
const mpImport = module.exports = main;
mpImport.createMpStream = pipeInterface;

// this is for CLI
if (require.main === module) {
	// Check if --ui flag is present
	const args = cliParams();

	// @ts-ignore
	if (args.ui) {
		// Start the web UI
		const { startUI } = require('./ui/server.js');
		startUI().catch((error) => {
			console.error('Failed to start UI:', error.message);
			process.exit(1);
		});
	} else {
		// Regular CLI import
		// @ts-ignore
		main(undefined, undefined, undefined, true).then(() => {
			//noop
		}).catch((e) => {
			console.log('\nUH OH! something went wrong; the error is:\n');
			console.error(e);
			process.exit(1);
		}).finally(() => {
			process.exit(0);
		});
	}
}
